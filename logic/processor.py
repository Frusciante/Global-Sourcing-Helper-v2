import time
import threading
import json
from urllib.parse import urljoin
import requests
import xml.etree.ElementTree as ET
import openai
from selenium.webdriver.common.by import By
import os
import re
from urllib.parse import urljoin

# [ëª¨ë“ˆ ì„í¬íŠ¸]
from logic.browser_manager import BrowserManager
from logic.excel_handler import ExcelHandler
from ui_components.manual_panel import ManualControlPanel 
from logic.utils import *

class SourcingProcessor:
    def __init__(self, config, log_callback, app_root=None):
        self.config = config
        self.log_callback = log_callback
        self.app_root = app_root
        self.is_running = False
        self.current_search_kw = ""
        
        self.cache_file = "brand_cache.json"
        self.brand_cache = self._load_cache()
        
        # 1. ê¸°ë³¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        self.browser = BrowserManager(self.log_callback)
        excel_file = self.config.get('EXCEL_FILE', 'result.xlsx')
        self.excel_handler = ExcelHandler(excel_file, self.log_callback, self.config)
        self.panel = None 

        raw_keys = self.config.get('AI_API_KEY', '') # ì„¤ì • íŒŒì¼ í‚¤ ì´ë¦„ ë³€ê²½ ê¶Œì¥
        self.api_keys = [k.strip() for k in raw_keys.split(',') if k.strip()]
        self.current_key_idx = 0
        self.model_candidates = [
            "gpt-oss-120b",
            "llama3.1-8b", 
            "qwen-3-235b-a22b-instruct-2507",
            "zai-glm-4.7"
        ]
        self.current_model_idx = 0
        self.client = None
        
        # 3. KIPRIS (ìƒí‘œê¶Œ) ì„¤ì • (ê¸°ì¡´ ì½”ë“œ ë³µì›)
        raw_kipris = self.config.get('KIPRIS_API_KEY', '')
        self.kipris_keys = [k.strip() for k in raw_kipris.split(',') if k.strip()]
        self.current_kipris_idx = 0

        # ì´ˆê¸° AI ì„¤ì •
        try:
            self._configure_ai()
        except Exception as e:
            self.log_callback(f"âš ï¸ [Init] AI ì´ˆê¸°í™” ì‹¤íŒ¨ (í‚¤ í™•ì¸ í•„ìš”): {e}")
            
    def _update_realtime_exchange_rate(self, url):
        """ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë¥¼ ì‚¬ìš©í•˜ì—¬ í™˜ìœ¨ ì—…ë°ì´íŠ¸"""
        if "rakuten" in url.lower(): target = "JPY"
        elif any(x in url.lower() for x in ['taobao', '1688', 'tmall']): target = "CNY"
        else: target = "USD"

        self.log_callback(f"ğŸŒ [Exchange] {target} í™˜ìœ¨ ì—…ë°ì´íŠ¸ ì¤‘...")
        
        # ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ í˜¸ì¶œ
        self.current_rate = fetch_naver_exchange_rate(target)
        self.log_callback(f"ğŸŒ [Exchange] {target} í™˜ìœ¨ ì—…ë°ì´íŠ¸ ì™„ë£Œ: {self.current_rate}")
            

    def _load_cache(self):
        """íŒŒì¼(ë¦¬ìŠ¤íŠ¸)ì—ì„œ ë¸”ë™ë¦¬ìŠ¤íŠ¸ë¥¼ ì½ì–´ì™€ ë©”ëª¨ë¦¬(ë”•ì…”ë„ˆë¦¬)ì— ë¡œë“œ"""
        if os.path.exists(self.cache_file):
            try:
                with open(self.cache_file, "r", encoding="utf-8") as f:
                    blacklist_list = json.load(f)
                    # ë¦¬ìŠ¤íŠ¸ í˜•íƒœ ["BRAND1", "BRAND2"]ë¥¼ 
                    # { "BRAND1": False, "BRAND2": False } í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ ë°˜í™˜
                    return {brand: False for brand in blacklist_list}
            except Exception as e:
                self.log_callback(f"âš ï¸ [Cache] ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
        return {}
    
    def _save_cache(self):
        """ì¤‘ë³µì„ ì›ì²œ ì°¨ë‹¨í•˜ë©° ë¸”ë™ë¦¬ìŠ¤íŠ¸ ì €ì¥"""
        try:
            # 1. ë”•ì…”ë„ˆë¦¬ì—ì„œ Falseì¸ ë¸Œëœë“œë§Œ ì¶”ì¶œ
            # 2. set()ìœ¼ë¡œ ê°ì‹¸ì„œ í˜¹ì‹œ ëª¨ë¥¼ ì¤‘ë³µ ì œê±°
            # 3. ë‹¤ì‹œ list()ë¡œ ë³€í™˜í•˜ì—¬ JSON ì €ì¥ ê°€ëŠ¥í•˜ê²Œ ë§Œë“¦
            blacklist_set = {k for k, v in self.brand_cache.items() if v is False}
        
            with open(self.cache_file, "w", encoding="utf-8") as f:
                json.dump(list(blacklist_set), f, ensure_ascii=False, indent=4)
            
        except Exception as e:
            self.log_callback(f"âš ï¸ [Cache] ì €ì¥ ì‹¤íŒ¨: {e}")

    def check_trademark(self, brand):
        """
        KIPRIS ìƒí‘œê¶Œ APIë¥¼ í†µí•´ ë¸Œëœë“œì˜ êµ­ë‚´ ë“±ë¡ ì—¬ë¶€ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
        - True: ìƒí‘œê¶Œ ì—†ìŒ (ì•ˆì „)
        - False: ìƒí‘œê¶Œ ë°œê²¬ (ìœ„í—˜)
        """
        if not brand or brand.upper() in ["NULL", "OEM", "NONE", "", "N/A"]:
            return True
        
        brand = brand.strip().upper()
        
        # 1. ìºì‹œ í™•ì¸ (ë¶ˆí•„ìš”í•œ API í˜¸ì¶œ ë°©ì§€)
        if brand in self.brand_cache:
            return self.brand_cache[brand]
        
        # KIPRIS í‚¤ê°€ ì—†ëŠ” ê²½ìš° ê¸°ë³¸ì ìœ¼ë¡œ ì•ˆì „í•˜ë‹¤ê³  ê°€ì •í•˜ê³  í†µê³¼
        if not self.kipris_keys:
            return True
    
        api_url = "https://plus.kipris.or.kr/kipo-api/kipi/trademarkInfoSearchService/getWordSearch"
        
        # 2. ë³´ìœ í•œ API í‚¤ ê°œìˆ˜ë§Œí¼ ì¬ì‹œë„ (í‚¤ ì†Œì§„ ì‹œ ë‹¤ìŒ í‚¤ë¡œ êµì²´)
        for _ in range(len(self.kipris_keys)):
            current_key = self.kipris_keys[self.current_kipris_idx]
            try:
                params = {
                    'searchString': brand,
                    'ServiceKey': current_key
                }
                res = requests.get(api_url, params=params, timeout=15)
                
                if res.status_code != 200:
                    raise Exception(f"HTTP Error {res.status_code}")
                
                # XML íŒŒì‹±
                root = ET.fromstring(res.content)
                count_tag = root.find(".//totalCount")
                
                if count_tag is None:
                    raise Exception("XML Parse Error (totalCount not found)")
                
                count = int(count_tag.text)
                is_safe = (count == 0) # ê²€ìƒ‰ ê²°ê³¼ê°€ 0ê±´ì´ì–´ì•¼ ì•ˆì „
                
                if not is_safe:
                    self.log_callback(f"   ğŸš« [KIPRIS] ìƒí‘œê¶Œ ë°œê²¬: '{brand}' ({count}ê±´)")
                
                # ê²°ê³¼ ìºì‹± ë° ì €ì¥
                self.brand_cache[brand] = is_safe
                self._save_cache() # ìºì‹œ íŒŒì¼ ì €ì¥ (ì„ íƒ ì‚¬í•­)
                
                return is_safe
    
            except Exception as e:
                # í˜„ì¬ í‚¤ ì‹¤íŒ¨ ì‹œ ì¸ë±ìŠ¤ ë³€ê²½ í›„ ë‹¤ìŒ í‚¤ ì‹œë„
                self.log_callback(f"   âš ï¸ KIPRIS API í‚¤ ì˜¤ë¥˜ (Index {self.current_kipris_idx}): {e}")
                self.current_kipris_idx = (self.current_kipris_idx + 1) % len(self.kipris_keys)
                continue
        
        # ëª¨ë“  í‚¤ê°€ ì‹¤íŒ¨í•  ê²½ìš° ì•ˆì „í•˜ë‹¤ê³  ê°€ì •í•˜ê³  í†µê³¼ì‹œí‚¤ê±°ë‚˜ ì—ëŸ¬ ë¡œê·¸ ë‚¨ê¹€
        self.log_callback(f"   âŒ KIPRIS ëª¨ë“  API í‚¤ í˜¸ì¶œ ì‹¤íŒ¨: '{brand}'")
        return True

    # ============================================================
    # [Core] AI & API í—¬í¼ ë©”ì„œë“œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    # ============================================================
    
    def _configure_ai(self):
        """Cerebras API í´ë¼ì´ì–¸íŠ¸ ì„¤ì • (OpenAI í˜¸í™˜)"""
        if not self.api_keys: return
        current_key = self.api_keys[self.current_key_idx]
        try:
            self.client = openai.OpenAI(
                base_url="https://api.cerebras.ai/v1",
                api_key=current_key
            )
        except Exception as e:
            self.client = None
            self.log_callback(f"âŒ [AI] ì„¤ì • ì˜¤ë¥˜: {e}")
            
    def _rotate_api_key(self):
        if len(self.api_keys) <= 1: return False
        
        self.current_key_idx = (self.current_key_idx + 1) % len(self.api_keys)
        self.log_callback(f"ğŸ”„ [AI] API í‚¤ êµì²´ ({self.current_key_idx + 1}/{len(self.api_keys)})")
        self._configure_ai()
        return True

    def _switch_model(self):
        if len(self.model_candidates) <= 1: return False
        self.current_model_idx = (self.current_model_idx + 1) % len(self.model_candidates)
        new_model = self.model_candidates[self.current_model_idx]
        self.log_callback(f"âš ï¸ [AI] ëª¨ë¸ ë³€ê²½ -> {new_model}")
        return True

    def _call_ai_with_retry(self, prompt, context=""):
        """
        Cerebras ìµœì í™” í˜¸ì¶œ ë¡œì§
        1ìˆœìœ„: ëª¨ë¸ ë¡œí…Œì´ì…˜ (RPM ë¶„ì‚°)
        2ìˆœìœ„: API í‚¤ ë¡œí…Œì´ì…˜
        3ìˆœìœ„: ëª¨ë“  ìì› ì†Œì§„ ì‹œ 60ì´ˆ ëŒ€ê¸° í›„ ìµœì¢… ì¬ì‹œë„ (Grand Cycle)
        """
        if not self.client: self._configure_ai()
        system_msg = "You are a professional e-commerce assistant. Provide direct answers. DO NOT include <think> tags or reasoning."
        if any(x in context for x in ["ì¶”ì¶œ", "ë¶„ì„", "ê²€ì¦"]):
            system_msg += " Always output in valid JSON format ONLY."
            system_msg += f"### OUTPUT INSTRUCTIONS ###\n"
            system_msg += f"- Response must be a single, valid JSON object.\n"
            system_msg += f"- DO NOT include any explanations or markdown outside the JSON block.\n"
            system_msg += f"- For Japanese or special characters, output them as-is without manual unicode escaping.\n"
            system_msg += f"- Prevent 'Invalid \\uXXXX escape' by not using raw backslashes unless necessary for valid JSON escaping.\n"
        else:
            system_msg += " Answer concisely without extra explanations."

        max_grand_cycles = 2 # ì „ì²´ ìì› ìˆœíšŒ íšŸìˆ˜ (ëŒ€ê¸° í¬í•¨)
        
        for cycle in range(max_grand_cycles):
            # í˜„ì¬ ê°€ìš©í•œ ëª¨ë“  'ëª¨ë¸ x í‚¤' ì¡°í•©ì˜ ìˆ˜ë§Œí¼ ë°˜ë³µ ì‹œë„
            total_resource_count = len(self.api_keys) * len(self.model_candidates)
            
            for attempt in range(total_resource_count):
                current_model = self.model_candidates[self.current_model_idx]
                
                try:
                    time.sleep(3) 

                    response = self.client.chat.completions.create(
                        model=current_model,
                        messages=[
                            {"role": "system", "content": system_msg},
                            {"role": "user", "content": prompt}
                        ],
                        temperature=0.1
                    )
                    raw_text = response.choices[0].message.content.strip()

                    # ------------------------------------------------------
                    # [í•µì‹¬] ìƒê° ê³¼ì • ë° ë¶ˆí•„ìš”í•œ í…ìŠ¤íŠ¸ ì œê±° ë¡œì§
                    # ------------------------------------------------------
                    # 1. <think> íƒœê·¸ì™€ ê·¸ ë‚´ìš© ì „ì²´ ì‚­ì œ
                    clean_text = re.sub(r'<think>.*?</think>', '', raw_text, flags=re.DOTALL).strip()

                    # 2. JSONì´ ì‹œì‘ë˜ëŠ” '{'ì™€ ëë‚˜ëŠ” '}'ì˜ ìœ„ì¹˜ë¥¼ ì°¾ì•„ì„œ ìŠ¬ë¼ì´ì‹±
                    start_idx = clean_text.find('{')
                    end_idx = clean_text.rfind('}')

                    if start_idx != -1 and end_idx != -1:
                        # ìˆœìˆ˜ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
                        final_res = clean_text[start_idx:end_idx + 1]
                    else:
                        # JSON í˜•íƒœê°€ ì•„ì˜ˆ ì—†ë‹¤ë©´ ë²ˆì—­ ê²°ê³¼ ë“±ìœ¼ë¡œ íŒë‹¨í•˜ì—¬ ê·¸ëŒ€ë¡œ ë°˜í™˜
                        final_res = clean_text

                    return final_res

                except Exception as e:
                    err_msg = str(e).lower()
                    
                    # 429(Rate Limit) ì—ëŸ¬ ë°œìƒ ì‹œ
                    if "429" in err_msg or "rate_limit" in err_msg:
                        self.log_callback(f"â³ [AI] {current_model} í•œë„ ì´ˆê³¼ ({context})")
                        
                        # 1ë‹¨ê³„: ë‹¤ìŒ ëª¨ë¸ë¡œ ì „í™˜
                        self.current_model_idx += 1
                        
                        # ëª¨ë“  ëª¨ë¸ì„ ë‹¤ ì¨ë´¤ë‹¤ë©´
                        if self.current_model_idx >= len(self.model_candidates):
                            self.current_model_idx = 0 # ëª¨ë¸ ì¸ë±ìŠ¤ ì´ˆê¸°í™”
                            
                            # 2ë‹¨ê³„: ë‹¤ìŒ API í‚¤ë¡œ ì „í™˜
                            if not self._rotate_api_key():
                                # ë” ì´ìƒ êµì²´í•  í‚¤ê°€ ì—†ë‹¤ë©´ ì´ë²ˆ Cycle ì¤‘ë‹¨
                                break 
                        continue # ë‹¤ìŒ ì¡°í•©ìœ¼ë¡œ ì¦‰ì‹œ ì¬ì‹œë„
                    
                    else:
                        self.log_callback(f"âš ï¸ [AI] ì˜¤ë¥˜ ë°œìƒ ({context}): {e}")
                        return None # ê¸°íƒ€ ì¹˜ëª…ì  ì˜¤ë¥˜ëŠ” ì¦‰ì‹œ ë°˜í™˜

            # [3ë‹¨ê³„] ëª¨ë“  í‚¤ì™€ ëª¨ë¸ì„ ë‹¤ ì¨ë´¤ëŠ”ë°ë„ ì‹¤íŒ¨í•œ ê²½ìš° (Grand Cycle)
            if cycle < max_grand_cycles - 1:
                wait_time = 60
                self.log_callback(f"ğŸ›‘ [AI] ëª¨ë“  ëª¨ë¸/í‚¤ ìì› ì†Œì§„ ({context}). {wait_time}ì´ˆ íœ´ì‹ í›„ ë§ˆì§€ë§‰ ì¬ì‹œë„...")
                time.sleep(wait_time)
            else:
                self.log_callback(f"âŒ [AI] ëª¨ë“  ì¬ì‹œë„ ì‹¤íŒ¨ ({context}). ì‘ì—…ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤.")
        
        return None

    # ============================================================
    # [Logic] ë¶„ì„ ë° ë°ì´í„° ì¶”ì¶œ (ê¸°ì¡´ ë¡œì§ ìœ ì§€)
    # ============================================================
    
    def extract_full_info(self, title, context_text="", search_keyword=""):
        """[1ë‹¨ê³„] AIëŠ” ì˜¤ì§ ìƒì„¸í˜ì´ì§€ì—ì„œ ì›ì–´ ë°ì´í„°ë¥¼ 'ì •í™•í•˜ê²Œ' ì¶”ì¶œí•˜ëŠ” ë° ì§‘ì¤‘í•©ë‹ˆë‹¤."""
        prompt = (
            f"Role: Data Extraction Specialist (No Translation)\n"
            f"Search Intent: '{search_keyword}'\n"
            f"Original Title: '{title}'\n"
            f"Context: '{context_text[:1500]}'\n\n"
            
            f"### CRITICAL TASK: EXCEL SEARCH KEYWORDS ###\n"
            f"1. **core_item**: The most general noun in Korean, not with adverbs or adjectives(e.g., 'ë ˆì¼ì „ë“±').\n"
            f"2. **alt_item**: A slightly broader synonym or related category name (e.g., 'ì¡°ëª…' or 'ì „ë“±').\n"
            f"   - **Goal**: These words must exist in a standard shopping mall category list. So the noun must be a leaf node in the category tree.\n\n"
            
            f"Output JSON format:\n"
            f"{{\n"
            f"  \"is_valid\": true,\n"
            f"  \"reason\": \"...\",\n"
            f"  \"product_title\": \"Original Language Title\",\n"
            f"  \"core_item\": \"Extracted Core Noun\",\n"
            f"  \"alt_item\": \"Extracted Alternate Category\",\n"
            f"  \"original_features\": [\"feat1\", \"feat2\", \"feat3\", \"feat4\", \"feat5\"]\n"
            f"}}"
        )
    
        res = self._call_ai_with_retry(prompt, "JSON ì •ë³´ ì¶”ì¶œ")
        if res:
            try:
                clean_json = res.replace('```json', '').replace('```', '').strip()
                return json.loads(clean_json)
            except Exception as e:
                self.log_callback(f"âš ï¸ [AI] ì›ì–´ ì¶”ì¶œ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None

    def detect_and_translate(self, url, keyword):
        """ì‡¼í•‘ëª° URLì— ë§ì¶° í‚¤ì›Œë“œ ë²ˆì—­"""
        target_lang = None
        if any(x in url for x in ['taobao', '1688', 'tmall']): target_lang = "zh-CN"
        elif any(x in url for x in ['amazon', 'ebay']): target_lang = "en"
        elif any(x in url for x in ['rakuten']): target_lang = "ja"
        
        # 2. ë²ˆì—­ ì‹¤í–‰
        if target_lang:
            try:
                translated = google_translator.translate(keyword, dest=target_lang, src='ko').text.strip()
            
                if translated:
                    cleaned = translated.strip()
                    self.log_callback(f"   ã„´ ğŸ”¤ ë²ˆì—­: {keyword} -> {cleaned}")
                    return cleaned
                
            except Exception as e:
                self.log_callback(f"   âš ï¸ í‚¤ì›Œë“œ ë²ˆì—­ ì‹¤íŒ¨: {e}")
            
        return keyword # ë²ˆì—­ ì‹¤íŒ¨í•˜ê±°ë‚˜ ëŒ€ìƒ ì–¸ì–´ê°€ ì—†ìœ¼ë©´ ì›ë³¸ í‚¤ì›Œë“œ ë°˜í™˜
    
    def refine_results(self, raw_data):
        """[2, 3ë‹¨ê³„] ë²ˆì—­ê¸° ë°ì´í„°ë¥¼ ì¬ë£Œ ì‚¼ì•„, AIê°€ 'ë„¤ì´í‹°ë¸Œ í•œêµ­ì–´'ë¡œ ì œëª©ì„ ì¬ì°½ì‘í•©ë‹ˆë‹¤."""
        if not raw_data or not raw_data.get('is_valid'):
            return raw_data

        # --- ê¸°ê³„ ë²ˆì—­ (ê¸°ì´ˆ ì¬ë£Œ ì¤€ë¹„) ---
        base_ko_title = translate_text(raw_data['product_title'])
        ko_features = translate_keywords_list(raw_data['original_features'])
        
        hint = raw_data.get('core_item', "")
        alt_hint = raw_data.get('alt_item', '')

        cp_candidates = self.excel_handler.get_category_candidates(hint, alt_hint, base_ko_title, 'coupang', limit=10)
        nv_candidates = self.excel_handler.get_category_candidates(hint, alt_hint, base_ko_title, 'naver', limit=10)
        
        self.log_callback(f"   ã„´ ğŸ“Š ì¹´í…Œê³ ë¦¬ í›„ë³´ (ì¿ íŒ¡): {cp_candidates}")
        self.log_callback(f"   ã„´ ğŸ“Š ì¹´í…Œê³ ë¦¬ í›„ë³´ (ë„¤ì´ë²„): {nv_candidates}")
    
    
        # --- AI í•œêµ­ì–´ ìµœì í™” (SEO ë° ë¬¸ì¥ ë‹¤ë“¬ê¸°) ---
        refine_prompt = (
            f"Role: Senior Korean E-commerce Merchandiser & SEO Copywriter\n"
            f"Base Material (Raw Translation of the title): '{base_ko_title}'\n"
            f"Base Material (Features): {', '.join(ko_features)}\n"
            f"Base Material (Coupang Category Candidates): {', '.join(cp_candidates)}\n"
            f"Base Material (Naver Category Candidates): {', '.join(nv_candidates)}\n"
            f"Original Brand: {raw_data.get('brand')}\n\n"
            
            f"### CRITICAL TASK 1: NATURAL REWRITING OF THE TITLE ###\n"
            f"1. **ESCAPE LITERAL TRANSLATION**: The 'Base Material' provided above might be an awkward, literal translation (ì§ì—­). Your primary mission is to REWRITE it into extremely natural, native-level Korean.\n"
            f"2. **SHOPPING MALL STYLE**: Format the title to be catchy and trustworthy for Korean customers on Naver or Coupang.\n"
            f"   - Format: [Brand] + Product Name + Essential Spec + Quantity (Keep it under 45 chars).\n"
            f"3. **SEO KEYWORDS**: Create 5 trendy keywords based on the 'natural' product name you created.\n"

            f"### CRITICAL TASK 2: SELECTION FOR COUPANG AND NAVER CATEGORY###\n"
            f"1. **CATEGORY MATCHING**: From the provided category candidates, select the one that best fits the product referring to the base title and features.\n"
            f"2. **CATEGORY FORMATTING**: Format the category as '[product code] category path>...' exactly as it appears in the candidate list. This is crucial for Excel matching later.\n"

            f"Output JSON format:\n"
            f"{{\n"
            f"  \"refined_title\": \"ìì—°ìŠ¤ëŸ½ê²Œ ì¬ì°½ì‘ëœ í•œêµ­ì–´ ìƒí’ˆëª…\",\n"
            f"  \"seo_keywords\": [\"í‚¤ì›Œë“œ1\", \"2\", \"3\", \"4\", \"5\"]\n"
            f"  \"refined_category_cp\": \"[product code] ì¿ íŒ¡>ì¹´í…Œê³ ë¦¬>ì „ì²´>ë¬¸ìì—´>ê·¸ëŒ€ë¡œ>ë³µì‚¬\",\n"
            f"  \"refined_category_nv\": \"[product code] ë„¤ì´ë²„>ì¹´í…Œê³ ë¦¬>ì „ì²´>ë¬¸ìì—´>ê·¸ëŒ€ë¡œ>ë³µì‚¬\"\n"
            f"}}\n\n"
            
        )
    
        refine_res = self._call_ai_with_retry(refine_prompt, "í•œêµ­ì–´ ì œëª© ì¬ê°€ê³µ")
        if refine_res:
            try:
                clean_json = refine_res.replace('```json', '').replace('```', '').strip()
                refined_data = json.loads(clean_json)
                
                raw_data['translated_title'] = refined_data['refined_title']
                raw_data['seo_keywords'] = refined_data['seo_keywords']
                raw_data['category_cp'] = refined_data['refined_category_cp']
                raw_data['category_nv'] = refined_data['refined_category_nv']
                
                self.log_callback(f"   ã„´ âœ¨ SEO ìµœì í™” ì™„ë£Œ (ì œëª©): {raw_data['translated_title']}")
                self.log_callback(f"   ã„´ âœ¨ SEO ìµœì í™” ì™„ë£Œ (í‚¤ì›Œë“œ): {raw_data['seo_keywords']}")
                self.log_callback(f"   ã„´ âœ¨ SEO ìµœì í™” ì™„ë£Œ (ì¿ íŒ¡ ì¹´í…Œê³ ë¦¬): {raw_data['category_cp']}")
                self.log_callback(f"   ã„´ âœ¨ SEO ìµœì í™” ì™„ë£Œ (ë„¤ì´ë²„ ì¹´í…Œê³ ë¦¬): {raw_data['category_nv']}")

                return raw_data
            except:
                self.log_callback(f"âš ï¸ [AI] í•œêµ­ì–´ ìµœì í™” JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë¬¸ ë°ì´í„°ë¡œ ì €ì¥: {refined_data[:100]}...")
                return raw_data
                
        return raw_data

    # [Callback] ìƒì„¸ í˜ì´ì§€ ì²˜ë¦¬ í•µì‹¬ ë¡œì§ (ìë™/ë°˜ìë™ ê³µìš©)
    # ============================================================
    def _process_product_callback(self, driver, raw_title):
        """
        BrowserManagerê°€ ìƒì„¸ í˜ì´ì§€ì— ì§„ì…í–ˆì„ ë•Œ í˜¸ì¶œë˜ëŠ” ì½œë°±.
        ê¸°ì¡´ processor.pyì˜ í•µì‹¬ ë¡œì§ì„ ì—¬ê¸°ì— ì´ì‹í–ˆìŠµë‹ˆë‹¤.
        """
        try:
            # 1. ìƒì„¸ í˜ì´ì§€ ë³¸ë¬¸ ì¶”ì¶œ (AI ë¶„ì„ìš©)
            try:
                body_text = driver.find_element(By.TAG_NAME, "body").text
            except:
                body_text = ""
                
            current_kw = getattr(self, 'current_search_kw', 'ìƒí’ˆ')

            self.log_callback("   ğŸ¤– [AI] ìƒí’ˆ ì •ë³´ ë¶„ì„ ì¤‘...")

            # 2. AI ì •ë³´ ì¶”ì¶œ (ë²ˆì—­ëœ ì œëª©, ë¸Œëœë“œ, íƒœê·¸ ë“±)
            info = self.extract_full_info(raw_title, body_text, current_kw)
            
            if not info or not info.get('is_valid', True):
                self.log_callback("   ğŸ—‘ï¸ [Skip] ìœ íš¨í•˜ì§€ ì•Šì€ ìƒí’ˆ")
                return False

            refined_info = self.refine_results(info)

            final_title = refined_info.get('translated_title', raw_title)
            brand = refined_info.get('brand', '')

            # 3. KIPRIS ìƒí‘œê¶Œ ê²€ì‚¬
            if not self.check_trademark(brand):
                return False # ìƒí‘œê¶Œ ì´ìŠˆë¡œ ì¤‘ë‹¨

            # 5. ì—‘ì…€ ì €ì¥
            data_row = {
                'translated_title': final_title,
                'url': driver.current_url,
                'tags': refined_info.get('seo_keywords', []),
                'cp_cat': refined_info.get('category_cp', ''),
                'nv_cat': refined_info.get('category_nv', ''),
                'manufacturer': refined_info.get('manufacturer', 'OEM'),
                'brand': brand,
                'model': refined_info.get('model', '')
            }
            
            if self.excel_handler.save_product(data_row):
                self.log_callback(f"   âœ… ì €ì¥ ì™„ë£Œ: {final_title[:15]}...")
                return True
            return False

        except Exception as e:
            self.log_callback(f"   âŒ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return False

    # ============================================================
    # [Flow] ì‹¤í–‰ ë° ì œì–´ (ë¶„ê¸° ë¡œì§ ì ìš©ë¨)
    # ============================================================
    def stop(self):
        self.is_running = False
        if self.panel:
            try: self.panel.destroy()
            except: pass
        self.browser.close()

    def run(self):
        """ì‘ì—… ì‹œì‘: URLì— ë”°ë¼ ëª¨ë“œ ìë™ ë¶„ê¸°"""
        self.is_running = True
        keywords = [k.strip() for k in self.config.get('TARGET_ITEMS', '').split(",") if k.strip()]
        urls = [u.strip() for u in self.config.get('SHOP_URLS', '').split(",") if u.strip()]
        max_count = int(self.config.get('ITEM_COUNT', 10))

        self.browser.start_driver()

        try:
            for shop_url in urls:
                if not self.is_running: break
                
                self._update_realtime_exchange_rate(shop_url)
                
                # ì¤‘êµ­ ì‚¬ì´íŠ¸ íŒë³„
                is_china = any(x in shop_url.lower() for x in ['taobao', '1688', 'tmall'])
                
                if is_china:
                    self.run_manual_mode(shop_url)
                else:
                    self.run_auto_mode(shop_url, keywords, max_count)
        finally:
            self.stop()
            self.log_callback("\nğŸ [Finish] ëª¨ë“  ì‘ì—… ì¢…ë£Œ")

    def run_manual_mode(self, url):
        """ë°˜ìë™ ëª¨ë“œ: ë¦¬ëª¨ì»¨ ì‚¬ìš©"""
        self.log_callback(f"\nğŸ‡¨ğŸ‡³ [Manual] ë°˜ìë™ ëª¨ë“œ: {url}")
        self.browser.driver.get(url)
        
        self.action_event = threading.Event()
        self.action_type = None 

        def on_collect():
            self.action_type = 'collect'; self.action_event.set()
        
        def on_stop():
            self.action_type = 'stop'; self.action_event.set(); self.is_running = False

        if self.app_root:
            self.app_root.after(0, lambda: self._create_panel(on_collect, on_stop))

        while self.is_running:
            self.action_event.clear()
            self.log_callback("   â³ [ëŒ€ê¸°] ë¦¬ëª¨ì»¨ 'ìˆ˜ì§‘' ë²„íŠ¼ ëŒ€ê¸°ì¤‘...")
            
            while not self.action_event.is_set():
                if not self.is_running: break
                time.sleep(0.5)
            
            if not self.is_running or self.action_type == 'stop': break

            if self.action_type == 'collect':
                title, _ = self.browser.get_current_page_info()
                if title:
                    # â˜… ì—¬ê¸°ì„œ AI ë¶„ì„ ë¡œì§(_process_product_callback)ì´ í˜¸ì¶œë©ë‹ˆë‹¤.
                    self.browser.process_current_page(self._process_product_callback)

        if self.app_root:
            self.app_root.after(0, lambda: self.panel.destroy() if self.panel else None)

    def _create_panel(self, c, s):
        self.panel = ManualControlPanel(self.app_root, c, s)

    def _get_search_url(self, base_url, keyword):
        """ì‡¼í•‘ëª°ë³„ ê²€ìƒ‰ íŒ¨í„´ì— ë§ëŠ” URL ìƒì„±"""
        base_url = base_url.rstrip('/')
        if "amazon" in base_url.lower():
            return f"{base_url}/s?k={keyword}"
        elif "rakuten" in base_url.lower():
            # ë¼ì¿ í…ì€ ì „ìš© ê²€ìƒ‰ ê²½ë¡œ ì‚¬ìš©ì´ ë” ì •í™•í•¨
            return f"https://search.rakuten.co.jp/search/mall/{keyword}/"
        # ê¸°ë³¸ê°’ (ì¼ë°˜ì ì¸ ì¿¼ë¦¬ íŒŒë¼ë¯¸í„° ì‚¬ìš©)
        return f"{base_url}/search?q={keyword}"
    
    def run_auto_mode(self, shop_url, keywords, max_count):
        
        for kw in keywords:
            translated_kw = self.detect_and_translate(shop_url, kw)
            total_saved_count = 0 
            page = 1 

            while total_saved_count < max_count and self.is_running:
                search_url = self._get_search_url(shop_url, translated_kw)
                if page > 1:
                    connector = "&" if "?" in search_url else "?"
                    if "amazon" in shop_url.lower(): search_url += f"{connector}page={page}"
                    elif "rakuten" in shop_url.lower(): search_url += f"{connector}p={page}"
                    else: search_url += f"{connector}page={page}"

                self.log_callback(f"\nğŸ“‘ [Page {page}] '{translated_kw}' ë¶„ì„ ì¤‘... (ì§„í–‰: {total_saved_count}/{max_count})")
                self.log_callback(f"ğŸŒ [Step 1] URL ì ‘ì† ì‹œë„ ì¤‘...")
                self.browser.driver.get(search_url)
                for i in range(3):
                    self.browser.driver.execute_script(f"window.scrollTo(0, {(i+1)*800});")
                    time.sleep(1.5)

                is_amazon = "amazon" in shop_url.lower()
                is_rakuten = "rakuten" in shop_url.lower()

                if is_amazon:
                    item_selector = "div.s-result-item[data-component-type='s-search-result'], div.s-card-container, .s-result-item"
                    price_selector = ".a-price .a-offscreen, .a-price-whole"
                elif is_rakuten:
                    item_selector = ".searchresultitem, [data-id], .dui-card.searchresultitem, div.searchresultitem, [data-index], .dui-card" 
                    price_selector = ".price--3zUvK, div[class*='price--'], .important"
                else: continue

                self.log_callback(f"ğŸ” [Step 2] ìƒí’ˆ ëª©ë¡ ì¶”ì¶œ ì‹œë„...")
                self.browser.driver.implicitly_wait(10)
                items = self.browser.driver.find_elements(By.CSS_SELECTOR, item_selector)
                self.log_callback(f"ğŸ“Š [Step 2] ë°œê²¬ëœ ìš”ì†Œ: {len(items)}ê°œ")
                
                if not items:
                    self.log_callback("âš ï¸ ìƒí’ˆ ëª©ë¡ì„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ìŒ í‚¤ì›Œë“œë¡œ ë„˜ì–´ê°‘ë‹ˆë‹¤.")
                    break

                target_links = []
                # ë¦¬ìŠ¤íŠ¸ ìŠ¤ìº” ì‹œì—ëŠ” ëŒ€ê¸° ì‹œê°„ì„ 0ìœ¼ë¡œ ì„¤ì •í•˜ì—¬ ì†ë„ í–¥ìƒ
                self.browser.driver.implicitly_wait(0)
                
                for idx, item in enumerate(items):
                    if (idx + 1) % 20 == 0:
                        self.log_callback(f"   â³ [{idx+1}/{len(items)}] í•­ëª© í•„í„°ë§ ì¤‘...")
                        
                    # -----------------------------------------------------------
                    # [ë””ë²„ê¹… ì¶”ê°€] 10ê°œë§ˆë‹¤ ìƒ˜í”Œ ì¶œë ¥ (ìµœëŒ€ 15ê°œ)
                    # -----------------------------------------------------------
                    if idx % 10 == 0:
                        try:
                            # ì¼ë‹¨ ì•„ë¬´ <a> íƒœê·¸ë‚˜ ê°€ì ¸ì™€ì„œ ì›ë³¸ í™•ì¸
                            raw_el = item.find_element(By.TAG_NAME, "a")
                            raw_href = raw_el.get_attribute("href")
                            raw_title = raw_el.get_attribute("title") or raw_el.text.strip()
                            
                            self.log_callback(f"ğŸ” [Sample] ì›ë³¸ ì œëª©: {raw_title[:20]}...")
                            self.log_callback(f"   ğŸ”— ì›ë³¸ ë§í¬: {raw_href[:50]}...")
                            
                            # ì•„ë§ˆì¡´ì´ë¼ë©´ ASIN ì¡´ì¬ ì—¬ë¶€ë„ í™•ì¸
                            if is_amazon:
                                raw_asin = item.get_attribute("data-asin")
                                self.log_callback(f"   ğŸ†” ASIN ì¡´ì¬ ì—¬ë¶€: {'O' if raw_asin else 'X'}")
                            
                        except:
                            pass
                    # -----------------------------------------------------------
                    
                    try:
                        # [1] ë§í¬ ë° ì œëª© ì¶”ì¶œ
                        try:
                            link_el = item.find_element(By.CSS_SELECTOR, "a[data-link='item']")
                        except:
                            try: link_el = item.find_element(By.CSS_SELECTOR, "a[class*='title-link']")
                            except:
                                try: link_el = item.find_element(By.CSS_SELECTOR, "h2 a")
                                except: link_el = item.find_element(By.TAG_NAME, "a")

                        link = link_el.get_attribute("href")
                        title = link_el.get_attribute("aria-label") or link_el.get_attribute("title") or link_el.text.strip()
                        
                        if not title:
                            try:
                                img_el = item.find_element(By.TAG_NAME, "img")
                                title = img_el.get_attribute("alt").strip()
                            except:
                                pass

                        # [2] ê²½ë¡œ ì •ê·œí™” ë° ìœ íš¨ì„± ê²€ì‚¬
                        if link and link.startswith("/"):
                            link = urljoin(shop_url, link)
                        
                        if not isinstance(link, str) or not link.startswith("http"):
                            continue
                        
                        if any(x in title for x in ['ì¤‘ê³ ', 'ä¸­å¤', 'Used', 'Pre-owned', 'Refurbished']):
                            self.log_callback(f"   ğŸ—‘ï¸ [Skip] ì¤‘ê³  ìƒí’ˆ í•„í„°ë§: {title[:30]}...")
                            continue

                        if is_amazon:
                            asin = item.get_attribute("data-asin")
                            if not asin: 
                                self.log_callback(f"   ğŸ—‘ï¸ [Skip] ì•„ë§ˆì¡´ ìƒí’ˆ í•„í„°ë§: {title[:30]}...")
                                continue

                        # [5] ê°€ê²© ì¶”ì¶œ ë° í•„í„°ë§
                        krw_price = 0
                        try:
                            price_el = item.find_element(By.CSS_SELECTOR, price_selector)
                            raw_price_text = price_el.get_attribute('textContent')
                            clean_price_str = re.sub(r'[^0-9.]', '', raw_price_text)
                            
                            if clean_price_str.count('.') > 1:
                                parts = clean_price_str.split('.')
                                clean_price_str = parts[0] + "." + "".join(parts[1:])
                            
                            if clean_price_str:
                                krw_price = float(clean_price_str) * self.current_rate
                        except:
                            pass # ê°€ê²© ëª» ì°¾ì•„ë„ ì¼ë‹¨ í†µê³¼ (ìƒì„¸í˜ì´ì§€ì—ì„œ ì¬í™•ì¸)
                        
                        self.log_callback(f"   ğŸ’° ê°€ê²© ì¶”ì¶œ: {krw_price:.0f}ì› (ì›ë³¸: '{raw_price_text if 'raw_price_text' in locals() else 'N/A'}')")

                        p_min = float(self.config.get('PRICE_MIN', 0))
                        p_max = float(self.config.get('PRICE_MAX', 0))

                        if krw_price > 0:
                            if (p_min > 0 and krw_price < p_min) or (p_max > 0 and krw_price > p_max):
                                self.log_callback(f"   ğŸ—‘ï¸ [Skip] ê°€ê²© í•„í„°ë§: {krw_price:.0f}ì› ({title[:30]}...)")
                                continue

                        # ìµœì¢… í†µê³¼ëœ ìƒí’ˆë§Œ ì¶”ê°€
                        target_links.append({'link': link, 'title': title})

                    except Exception:
                        continue

                # ìŠ¤ìº” ì™„ë£Œ í›„ ëŒ€ê¸° ì‹œê°„ ì›ë³µ
                self.browser.driver.implicitly_wait(10)
                self.log_callback(f"ğŸš€ [Step 3] ë¶„ì„ ëŒ€ìƒ ìƒí’ˆ {len(target_links)}ê°œ í™•ì •.")

                # [6] ìƒì„¸ í˜ì´ì§€ ë°©ë¬¸ ë° AI ë¶„ì„
                for prod in target_links:
                    if total_saved_count >= max_count or not self.is_running: break
                    
                    self.log_callback(f"   ğŸš€ [ì‹œë„] {prod['title'][:20]}...")
                    try:
                        self.browser.driver.get(prod['link'])
                        time.sleep(2)
                        
                        if self._process_product_callback(self.browser.driver, prod['title']):
                            total_saved_count += 1
                            self.log_callback(f"      âœ… í˜„ì¬ {total_saved_count}/{max_count}ê°œ ì €ì¥ ì™„ë£Œ")
                    except Exception as e:
                        self.log_callback(f"   âš ï¸ ìƒì„¸í˜ì´ì§€ ì˜¤ë¥˜: {e}")
                        continue

                if total_saved_count < max_count:
                    page += 1
                    self.log_callback(f"ğŸ”„ ìˆ˜ëŸ‰ ë¯¸ë‹¬({total_saved_count}/{max_count}). ë‹¤ìŒ {page}í˜ì´ì§€ë¡œ ì´ë™!")
                else:
                    self.log_callback(f"ğŸŠ ëª©í‘œ ìˆ˜ëŸ‰({max_count}ê°œ) ë‹¬ì„± ì™„ë£Œ!")

            self.log_callback(f"âœ… '{kw}' í‚¤ì›Œë“œ ìµœì¢… ì¢…ë£Œ")